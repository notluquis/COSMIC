{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725abd69-73ff-4def-a469-73db8f920235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T15:39:46.216397Z",
     "iopub.status.busy": "2025-09-07T15:39:46.216222Z",
     "iopub.status.idle": "2025-09-07T15:39:49.508524Z",
     "shell.execute_reply": "2025-09-07T15:39:49.508227Z",
     "shell.execute_reply.started": "2025-09-07T15:39:46.216379Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Celda 1: imports y helpers de IO ---\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from cluster_analysis import ClusterAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "import pytensor.tensor as pt\n",
    "from types import MethodType\n",
    "\n",
    "# helpers\n",
    "def save_npz(path, **arrays):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    np.savez_compressed(path, **arrays)\n",
    "\n",
    "def save_pkl(path, obj):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_pkl(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# chequeos rápidos de reproducibilidad\n",
    "def fingerprint(arr, k=5):\n",
    "    \"\"\"Hash simple: primeros k valores y shape/dtype.\"\"\"\n",
    "    arr = np.asarray(arr).ravel()\n",
    "    head = arr[:k]\n",
    "    return dict(shape=arr.shape, dtype=str(arr.dtype),\n",
    "                head=np.array(head, copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9711c0-0109-4401-b199-159ba69e8cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T15:39:49.510544Z",
     "iopub.status.busy": "2025-09-07T15:39:49.510337Z",
     "iopub.status.idle": "2025-09-07T15:39:49.512182Z",
     "shell.execute_reply": "2025-09-07T15:39:49.511962Z",
     "shell.execute_reply.started": "2025-09-07T15:39:49.510533Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Celda 2: RNG y observaciones ---\n",
    "rng = np.random.default_rng(42)  # semilla fija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902bbf30-0e79-4165-932a-962fec2064cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T15:39:49.512523Z",
     "iopub.status.busy": "2025-09-07T15:39:49.512441Z",
     "iopub.status.idle": "2025-09-07T15:39:49.517554Z",
     "shell.execute_reply": "2025-09-07T15:39:49.517328Z",
     "shell.execute_reply.started": "2025-09-07T15:39:49.512514Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DataLoader initialized with file path: /Users/notluquis/Library/Mobile Documents/com~apple~CloudDocs/Investigación/COSMIC/COSMIC/data.dill\n",
      "Masked data handled and replaced with NaN.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/Users/notluquis/Library/Mobile Documents/com~apple~CloudDocs/Investigación/COSMIC/COSMIC/data.ecsv\"\n",
    "\n",
    "ca = ClusterAnalyzer(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1947f7ec-a427-4f61-9e91-ec945b2a2c14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T15:39:56.621078Z",
     "iopub.status.busy": "2025-09-07T15:39:56.620598Z",
     "iopub.status.idle": "2025-09-07T15:39:56.641092Z",
     "shell.execute_reply": "2025-09-07T15:39:56.640420Z",
     "shell.execute_reply.started": "2025-09-07T15:39:56.621051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>count</th>\n",
       "      <th>fraction</th>\n",
       "      <th>persistence</th>\n",
       "      <th>mean_prob</th>\n",
       "      <th>median_prob</th>\n",
       "      <th>min_prob</th>\n",
       "      <th>max_prob</th>\n",
       "      <th>iqr_prob</th>\n",
       "      <th>centroid_pmra</th>\n",
       "      <th>centroid_pmdec</th>\n",
       "      <th>mean_dist2centroid</th>\n",
       "      <th>std_dist2centroid</th>\n",
       "      <th>pmra_range</th>\n",
       "      <th>pmdec_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.780547</td>\n",
       "      <td>0.807082</td>\n",
       "      <td>0.500444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.317599</td>\n",
       "      <td>2.514274</td>\n",
       "      <td>-1.699468</td>\n",
       "      <td>0.221924</td>\n",
       "      <td>0.102786</td>\n",
       "      <td>0.903669</td>\n",
       "      <td>0.733876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster  count  fraction  persistence  mean_prob  median_prob  min_prob  \\\n",
       "0       12    331       1.0          NaN   0.780547     0.807082  0.500444   \n",
       "\n",
       "   max_prob  iqr_prob  centroid_pmra  centroid_pmdec  mean_dist2centroid  \\\n",
       "0       1.0  0.317599       2.514274       -1.699468            0.221924   \n",
       "\n",
       "   std_dist2centroid  pmra_range  pmdec_range  \n",
       "0           0.102786    0.903669     0.733876  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca.clusters_summary(include_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e4c713-1f23-4fb5-95b0-28dc5d163b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-07T20:51:16.883102Z",
     "iopub.status.busy": "2025-09-07T20:51:16.874135Z",
     "iopub.status.idle": "2025-09-07T20:51:19.800652Z",
     "shell.execute_reply": "2025-09-07T20:51:19.800039Z",
     "shell.execute_reply.started": "2025-09-07T20:51:16.882858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instantiating isochrones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asteca\n",
    "isochs = asteca.Isochrones(isochs_path=\"/Users/notluquis/Library/Mobile Documents/com~apple~CloudDocs/Investigación/NGC6383/MIST\",\n",
    "                           model='MIST',\n",
    "                           magnitude=\"Gaia_G_EDR3\",\n",
    "                           magnitude_effl=6390.7,\n",
    "                           color=(\"Gaia_BP_EDR3\",\"Gaia_RP_EDR3\"),\n",
    "                           color_effl = (5182.6,7825.1),\n",
    "                           #color2 = (\"Gaia_RP_EDR3\",\"2MASS_J\"),\n",
    "                           #color2_effl = (7825.1, 12375.60),\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd488b-f040-4500-9dae-ec177fe141f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ca.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5749d-5018-4a4f-8acc-b2bccd3415fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cluster = asteca.Cluster(\n",
    "    ra=df[\"ra\"],\n",
    "    dec=df[\"dec\"],\n",
    "    pmra=df[\"pmra\"],\n",
    "    pmde=df[\"pmdec\"],\n",
    "    plx=df[\"parallax\"],\n",
    "    e_pmra=df[\"pmra_error\"],\n",
    "    e_pmde=df[\"pmdec_error\"],\n",
    "    e_plx=df[\"parallax_error\"],\n",
    "    magnitude=df['Gmag'],\n",
    "    e_mag=df[\"e_Gmag\"],\n",
    "    color=df[\"G_BPmag\"] - df[\"G_RPmag\"],\n",
    "    e_color=df['e_BP_RP'],\n",
    "    #color2=df[\"G_RPmag\"] - df[\"j_m\"],\n",
    "    #e_color2 = df['e_RP_J']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91501938-de6c-40ea-8d91-0aee05799dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthcl = asteca.Synthetic(isochs)\n",
    "\n",
    "synthcl.calibrate(my_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f69d1e-1e27-48f6-bf83-5c7da6aa0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- mover isócrona (PT) ---\n",
    "def move_isochrone_pt(iso_np, m_ini_idx, dm, binar_flag=True):\n",
    "    \"\"\"\n",
    "    iso_np: np.ndarray con forma (Nd, Ni)\n",
    "    m_ini_idx: índice entero de masa inicial\n",
    "    dm: float\n",
    "    \"\"\"\n",
    "    # asegurar tipos correctos\n",
    "    m_ini_idx = int(m_ini_idx)          # <- clave\n",
    "    Xm  = pt.as_tensor_variable(np.asarray(iso_np, dtype=np.float64))\n",
    "    dm_ = pt.as_tensor_variable(float(dm), dtype=\"float64\")\n",
    "\n",
    "    # magnitud principal\n",
    "    Xm = pt.set_subtensor(Xm[0, :], Xm[0, :] + dm_)\n",
    "\n",
    "    # magnitud binaria (si corresponde y existe esa fila)\n",
    "    if binar_flag:\n",
    "        idx_bin_mag = m_ini_idx + 2\n",
    "        if idx_bin_mag < iso_np.shape[0]:\n",
    "            Xm = pt.set_subtensor(Xm[idx_bin_mag, :], Xm[idx_bin_mag, :] + dm_)\n",
    "\n",
    "    # evaluar a numpy\n",
    "    return np.asarray(Xm.eval(), dtype=np.float64)\n",
    "\n",
    "def cut_max_mag_pt(iso_np: np.ndarray, max_mag_syn: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Versión PyTensor-friendly del corte por magnitud máxima.\n",
    "    Mantengo el enmascarado final en NumPy para evitar lógica booleana simbólica.\n",
    "    \"\"\"\n",
    "    # simbólico (no imprescindible, pero coherente)\n",
    "    X = pt.as_tensor_variable(iso_np)\n",
    "    mag = X[0, :]                              # (N,)\n",
    "    msk = pt.lt(mag, max_mag_syn)              # boolean simbólico\n",
    "    msk_np = np.asarray(msk.eval(), dtype=bool)\n",
    "    return iso_np[:, msk_np]\n",
    "\n",
    "def extinction_pt(\n",
    "    ext_law: str,\n",
    "    ext_coefs: list,\n",
    "    rand_norm: np.ndarray,\n",
    "    rand_unif: np.ndarray,\n",
    "    DR_distribution: str,\n",
    "    m_ini_idx: int,\n",
    "    binar_flag: bool,\n",
    "    Av: float,\n",
    "    dr: float,\n",
    "    Rv: float,\n",
    "    iso_np: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extinción en PyTensor para CCMO y GAIADR3 (incluye DR uniform/normal).\n",
    "    Para GAIADR3 usa la misma función 'dustapprox' del módulo original\n",
    "    (se mantiene el resultado numéricamente idéntico).\n",
    "    \"\"\"\n",
    "    from asteca.modules import synth_cluster_priv as scp\n",
    "\n",
    "    # índices SIEMPRE como enteros Python\n",
    "    m_ini_idx = int(m_ini_idx)\n",
    "    idx_bin_mag = m_ini_idx + 2\n",
    "    idx_bin_c1  = m_ini_idx + 3\n",
    "    idx_bin_c2  = m_ini_idx + 4\n",
    "\n",
    "    # Trabajamos sobre copia numpy (la función original modifica in-place)\n",
    "    iso = np.array(iso_np, copy=True)\n",
    "    Ns  = iso.shape[-1]\n",
    "\n",
    "    # ----- DR (differential reddening) -----\n",
    "    if dr > 0.0:\n",
    "        if DR_distribution == \"uniform\":\n",
    "            # en el original: (2*U-1)*dr, clip en Av>=0\n",
    "            dr_arr = (2.0 * rand_unif[:Ns] - 1.0) * dr\n",
    "        elif DR_distribution == \"normal\":\n",
    "            dr_arr = rand_norm[:Ns] * dr\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown DR_distribution: {DR_distribution}\")\n",
    "        Av_dr = np.clip(Av + dr_arr, a_min=0.0, a_max=np.inf)\n",
    "    else:\n",
    "        # sin DR: escalar (o vector constante)\n",
    "        Av_dr = Av\n",
    "\n",
    "    # ----- Coeficientes de extinción -----\n",
    "    if ext_law == \"CCMO\":\n",
    "        # Magnitud\n",
    "        ec_mag  = ext_coefs[0][0] + ext_coefs[0][1] / Rv\n",
    "        # Primer color\n",
    "        ec_col1 = (ext_coefs[1][0][0] + ext_coefs[1][0][1] / Rv) - \\\n",
    "                  (ext_coefs[1][1][0] + ext_coefs[1][1][1] / Rv)\n",
    "        # Segundo color (opcional)\n",
    "        has_c2  = len(ext_coefs) > 2\n",
    "        if has_c2:\n",
    "            ec_col2 = (ext_coefs[2][0][0] + ext_coefs[2][0][1] / Rv) - \\\n",
    "                      (ext_coefs[2][1][0] + ext_coefs[2][1][1] / Rv)\n",
    "\n",
    "    elif ext_law == \"GAIADR3\":\n",
    "        # Usa la misma aproximación del código original\n",
    "        # Retorna coeficientes efectivos (dependen de color BP-RP y Av_dr)\n",
    "        # Firma original: ec_mag, ec_col1 = dustapprox(BP_RP, Av_dr)\n",
    "        BPmRP = iso[1]  # primer color\n",
    "        ec_mag, ec_col1 = scp.dustapprox(BPmRP, Av_dr)\n",
    "        has_c2  = False  # el modelo DR3 afecta \"color2\" vía CCMO (no está definido aquí)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown extinction law: {ext_law}\")\n",
    "\n",
    "    # A_x y E_x\n",
    "    Ax  = ec_mag  * Av_dr\n",
    "    Ex1 = ec_col1 * Av_dr\n",
    "\n",
    "    # Asegura forma vector si corresponde\n",
    "    if np.ndim(Ax) == 0:\n",
    "        Ax  = np.full(Ns, Ax, dtype=float)\n",
    "    if np.ndim(Ex1) == 0:\n",
    "        Ex1 = np.full(Ns, Ex1, dtype=float)\n",
    "\n",
    "    # Aplicar a magnitud y primer color\n",
    "    iso[0] += Ax\n",
    "    iso[1] += Ex1\n",
    "\n",
    "    # Binario (si corresponde y existen columnas)\n",
    "    if binar_flag:\n",
    "        if idx_bin_mag < iso.shape[0]:\n",
    "            iso[idx_bin_mag] += Ax\n",
    "        if idx_bin_c1  < iso.shape[0]:\n",
    "            iso[idx_bin_c1] += Ex1\n",
    "\n",
    "    # Segundo color, solo si CCMO trae coef y la isocrona lo tiene\n",
    "    if ext_law == \"CCMO\" and has_c2 and iso.shape[0] > 2:\n",
    "        Ex2 = ec_col2 * Av_dr\n",
    "        if np.ndim(Ex2) == 0:\n",
    "            Ex2 = np.full(Ns, Ex2, dtype=float)\n",
    "        iso[2] += Ex2\n",
    "        if binar_flag and idx_bin_c2 < iso.shape[0]:\n",
    "            iso[idx_bin_c2] += Ex2\n",
    "\n",
    "    return iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231833e2-e895-4ce3-bed8-382a99deec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2(self, params: dict, N_stars: int = 100) -> np.ndarray:\n",
    "    from asteca.modules import synth_cluster_priv as scp\n",
    "\n",
    "    try:\n",
    "        # Del cluster calibrado\n",
    "        max_mag_syn   = self.max_mag_syn_obs\n",
    "        N_synth_stars = self.N_stars_obs\n",
    "        err_dist_synth = self.err_dist_obs\n",
    "    except AttributeError:\n",
    "        max_mag_syn   = np.inf\n",
    "        N_synth_stars = int(N_stars)\n",
    "        err_dist_synth = []\n",
    "\n",
    "    # Parámetros efectivos y pesos de (met, loga)\n",
    "    met, loga, alpha, beta, av, dr, rv, dm, ml, mh, al, ah = scp.properModel(\n",
    "        self.met_age_dict, self.def_params, params\n",
    "    )\n",
    "\n",
    "    # Isochrone fija o promedio ponderado\n",
    "    if ml == al == mh == ah == 0:\n",
    "        isochrone = np.array(self.theor_tracks[0][0])\n",
    "    else:\n",
    "        isochrone = scp.zaWAverage(\n",
    "            self.theor_tracks, self.met_age_dict, self.m_ini_idx,\n",
    "            met, loga, ml, mh, al, ah\n",
    "        )\n",
    "\n",
    "    # Flag de binariedad\n",
    "    binar_flag = not (alpha == 0.0 and beta == 0.0)\n",
    "\n",
    "    # (1) mover por distancia -> PyTensor\n",
    "    isoch_moved = move_isochrone_pt(\n",
    "        isochrone, int(self.m_ini_idx), float(dm), binar_flag\n",
    "    )\n",
    "\n",
    "    # (2) extinción -> PyTensor (CCMO / GAIADR3, con o sin DR)\n",
    "    isoch_extin = extinction_pt(\n",
    "        ext_law      = self.ext_law,\n",
    "        ext_coefs    = self.ext_coefs,\n",
    "        rand_norm    = self.rand_floats[\"norm\"][0],\n",
    "        rand_unif    = self.rand_floats[\"unif\"][0],\n",
    "        DR_distribution = self.DR_distribution,\n",
    "        m_ini_idx    = int(self.m_ini_idx),\n",
    "        binar_flag   = binar_flag,\n",
    "        Av           = float(av),\n",
    "        dr           = float(dr),\n",
    "        Rv           = float(rv),\n",
    "        iso_np       = isoch_moved,\n",
    "    )\n",
    "\n",
    "    # (3) corte por magnitud máxima -> PyTensor-friendly\n",
    "    isoch_cut = cut_max_mag_pt(isoch_extin, float(max_mag_syn))\n",
    "    if not isoch_cut.any():\n",
    "        return np.array([])\n",
    "\n",
    "    # Atajo para devolver isócrona recortada\n",
    "    if N_stars == -1:\n",
    "        return isoch_cut\n",
    "\n",
    "    # (4) interpolar IMF\n",
    "    isoch_mass = scp.mass_interp(\n",
    "        isoch_cut,\n",
    "        int(self.m_ini_idx),\n",
    "        self.st_dist_mass[ml][al],\n",
    "        int(N_synth_stars),\n",
    "        binar_flag,\n",
    "    )\n",
    "    if not isoch_mass.any():\n",
    "        return np.array([])\n",
    "\n",
    "    # (5) asignar binariedad\n",
    "    isoch_binar = scp.binarity(\n",
    "        float(alpha), float(beta), binar_flag, int(self.m_ini_idx),\n",
    "        self.rand_floats[\"unif\"][1], isoch_mass\n",
    "    )\n",
    "\n",
    "    # (6) añadir errores fotométricos\n",
    "    synth_clust = scp.add_errors(isoch_binar, err_dist_synth)\n",
    "\n",
    "    return synth_clust\n",
    "\n",
    "# bind al objeto\n",
    "synthcl.generate_2 = MethodType(generate_2, synthcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d7816-5d50-4281-8f92-006d95cf83b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_min  = float(isochs.met_age_dict['met'][0])\n",
    "met_max  = float(isochs.met_age_dict['met'][-1])\n",
    "loga_min = float(isochs.met_age_dict['loga'][0])\n",
    "loga_max = float(isochs.met_age_dict['loga'][-1])\n",
    "\n",
    "M_MET, M_LOGA = 10,10\n",
    "met_grid  = np.linspace(met_min,  met_max,  M_MET,  dtype=float)\n",
    "loga_grid = np.linspace(loga_min, loga_max, M_LOGA, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eab53d-a1b9-48bd-b43e-be72316e3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_clusters(syn: np.ndarray,\n",
    "                     syn2: np.ndarray,\n",
    "                     rtol: float = 0.0,\n",
    "                     atol: float = 0.0,\n",
    "                     topk: int = 10,\n",
    "                     name1=\"generate\",\n",
    "                     name2=\"generate_2\",\n",
    "                     verbose=True):\n",
    "    \"\"\"\n",
    "    Compara dos clusters (features x Nstars). Devuelve dict con métricas y,\n",
    "    si verbose=True, imprime diagnóstico detallado.\n",
    "    \"\"\"\n",
    "    out = {\n",
    "        \"ok\": False, \"reason\": None,\n",
    "        \"shape1\": None, \"shape2\": None,\n",
    "        \"n\": 0, \"n_nan_equal\": 0, \"n_checked\": 0,\n",
    "        \"max_abs\": np.nan, \"max_rel\": np.nan,\n",
    "        \"p95_abs\": np.nan, \"mean_abs\": np.nan,\n",
    "        \"violations\": 0, \"viol_idx\": None,\n",
    "        \"topk\": []\n",
    "    }\n",
    "\n",
    "    # 0) forma\n",
    "    out[\"shape1\"], out[\"shape2\"] = syn.shape, syn2.shape\n",
    "    if syn.shape != syn2.shape:\n",
    "        out[\"reason\"] = \"shape_mismatch\"\n",
    "        if verbose:\n",
    "            print(f\"[X] Shape mismatch: {name1}{syn.shape} vs {name2}{syn2.shape}\")\n",
    "        return out\n",
    "\n",
    "    # 1) patrón de NaNs\n",
    "    n1 = np.isnan(syn)\n",
    "    n2 = np.isnan(syn2)\n",
    "    if not np.array_equal(n1, n2):\n",
    "        out[\"reason\"] = \"nan_pattern_mismatch\"\n",
    "        if verbose:\n",
    "            diff_mask = n1 ^ n2\n",
    "            f_idx, s_idx = np.where(diff_mask)\n",
    "            print(f\"[X] NaN pattern mismatch en {diff_mask.sum()} posiciones.\")\n",
    "            print(\"  Ejemplo (feature, star):\", list(zip(f_idx[:10], s_idx[:10])))\n",
    "        return out\n",
    "\n",
    "    # 2) compara valores sólo donde ambos son finitos\n",
    "    fin = (~n1) & (~n2)\n",
    "    out[\"n\"] = syn.size\n",
    "    out[\"n_nan_equal\"] = np.count_nonzero(n1)  # == n2\n",
    "    out[\"n_checked\"] = fin.sum()\n",
    "    if out[\"n_checked\"] == 0:\n",
    "        out[\"ok\"] = True\n",
    "        out[\"reason\"] = \"all_nan_or_empty\"\n",
    "        if verbose:\n",
    "            print(\"[=] No hay elementos finitos que comparar (todo NaN/vacío).\")\n",
    "        return out\n",
    "\n",
    "    a = syn[fin].astype(np.float64, copy=False)\n",
    "    b = syn2[fin].astype(np.float64, copy=False)\n",
    "\n",
    "    absdiff = np.abs(a - b)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # rel = |a-b| / max(|b|, tiny)\n",
    "        denom = np.maximum(np.abs(b), np.finfo(np.float64).tiny)\n",
    "        reldiff = absdiff / denom\n",
    "\n",
    "    # métricas\n",
    "    out[\"max_abs\"]  = float(absdiff.max(initial=np.nan))\n",
    "    out[\"p95_abs\"]  = float(np.percentile(absdiff, 95))\n",
    "    out[\"mean_abs\"] = float(absdiff.mean())\n",
    "    out[\"max_rel\"]  = float(np.nanmax(reldiff))\n",
    "\n",
    "    # violaciones estrictas con rtol/atol dados\n",
    "    viol_mask = absdiff > (atol + rtol * np.abs(b))\n",
    "    out[\"violations\"] = int(viol_mask.sum())\n",
    "\n",
    "    # top-k diferencias\n",
    "    if out[\"n_checked\"] > 0:\n",
    "        if topk > 0:\n",
    "            # índices de top-k por diferencia absoluta\n",
    "            idx_sorted = np.argsort(-absdiff)[:topk]\n",
    "            # mapear a (feature, star)\n",
    "            feat_idx, star_idx = np.where(fin)\n",
    "            for idx in idx_sorted:\n",
    "                f = int(feat_idx[idx]); s = int(star_idx[idx])\n",
    "                out[\"topk\"].append({\n",
    "                    \"feat\": f, \"star\": s,\n",
    "                    f\"{name1}\": float(syn[f, s]),\n",
    "                    f\"{name2}\": float(syn2[f, s]),\n",
    "                    \"absdiff\": float(absdiff[idx]),\n",
    "                    \"reldiff\": float(reldiff[idx])\n",
    "                })\n",
    "            out[\"viol_idx\"] = np.column_stack([feat_idx[viol_mask], star_idx[viol_mask]])\n",
    "\n",
    "    # decide ok / not ok\n",
    "    out[\"ok\"] = (out[\"violations\"] == 0)\n",
    "    out[\"reason\"] = \"ok\" if out[\"ok\"] else \"violations\"\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[=] Comparación {name1} vs {name2}:\")\n",
    "        print(f\"    shape: {syn.shape}, finitos comparados: {out['n_checked']}, NaNs coincidentes: {out['n_nan_equal']}\")\n",
    "        print(f\"    max|Δ|={out['max_abs']:.3e}, p95|Δ|={out['p95_abs']:.3e}, mean|Δ|={out['mean_abs']:.3e}, max rel={out['max_rel']:.3e}\")\n",
    "        print(f\"    tolerancias: rtol={rtol}, atol={atol} → violaciones={out['violations']}\")\n",
    "        if out[\"topk\"]:\n",
    "            print(\"    Top-k diferencias:\")\n",
    "            for k, rec in enumerate(out[\"topk\"], 1):\n",
    "                print(f\"      #{k} (feat={rec['feat']}, star={rec['star']}): \"\n",
    "                      f\"{name1}={rec[name1]:.15g}, {name2}={rec[name2]:.15g}, \"\n",
    "                      f\"|Δ|={rec['absdiff']:.3e}, rel={rec['reldiff']:.3e}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf19f9-99a3-4e7d-8d69-1cf7b6a5b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_min  = float(isochs.met_age_dict['met'][0])\n",
    "met_max  = float(isochs.met_age_dict['met'][-1])\n",
    "loga_min = float(isochs.met_age_dict['loga'][0])\n",
    "loga_max = float(isochs.met_age_dict['loga'][-1])\n",
    "\n",
    "M_MET, M_LOGA = 10,10\n",
    "met_grid  = np.linspace(met_min,  met_max,  M_MET,  dtype=float)\n",
    "loga_grid = np.linspace(loga_min, loga_max, M_LOGA, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517749b9-9161-4c4a-adf8-fe56029bc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtol, atol = 0.0, 0.0  # pide igualdad bit a bit en float64 (si no hay reordenamientos)\n",
    "mismatches = []\n",
    "\n",
    "for i, met in enumerate(tqdm(met_grid, desc=\"met grid\")):\n",
    "    for j, loga in enumerate(loga_grid):\n",
    "        pars = {\"met\": float(met), \"loga\": float(loga), \"dm\": 0.0, \"Av\": 0.0}\n",
    "        syn  = synthcl.generate(pars)\n",
    "        syn2 = synthcl.generate_2(pars)\n",
    "\n",
    "        # salta vacíos\n",
    "        if syn.size == 0 and syn2.size == 0:\n",
    "            continue\n",
    "        if syn.size == 0 or syn2.size == 0:\n",
    "            print(f\"[{i},{j}] uno vacío: shapes {syn.shape} vs {syn2.shape}\")\n",
    "            mismatches.append((i, j, \"empty\"))\n",
    "            continue\n",
    "\n",
    "        rep = compare_clusters(syn, syn2, rtol=rtol, atol=atol, topk=5, verbose=False)\n",
    "        if not rep[\"ok\"]:\n",
    "            mismatches.append((i, j, rep))\n",
    "\n",
    "print(f\"Total celdas: {len(met_grid)*len(loga_grid)}\")\n",
    "print(f\"No equivalentes: {len(mismatches)}\")\n",
    "if mismatches:\n",
    "    i, j, rep = mismatches[0]\n",
    "    print(f\"Primer mismatch en (i={i}, j={j}): motivo={rep['reason']}\")\n",
    "    # puedes imprimir rep completo si quieres\n",
    "    _ = compare_clusters(synthcl.generate(\n",
    "            {\"met\": float(met_grid[i]), \"loga\": float(loga_grid[j]), \"dm\": 0.0, \"Av\": 0.0}\n",
    "        ),\n",
    "        synthcl.generate_2(\n",
    "            {\"met\": float(met_grid[i]), \"loga\": float(loga_grid[j]), \"dm\": 0.0, \"Av\": 0.0}\n",
    "        ),\n",
    "        rtol=rtol, atol=atol, topk=10, verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708081ce-07b2-40d5-8676-80d8d77625d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef058c13-f0a5-43a7-870c-4134fb7a9d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cccef1-61a7-4983-9ad2-972401e55854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82948f8e-16a6-4951-ac45-fdcc8a55f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga directa desde ca.data (QTable)\n",
    "T = ca.data  \n",
    "\n",
    "# Columnas de magnitud y colores\n",
    "mag_obs    = np.array(T[\"Gmag\"])       # magnitud\n",
    "color1_obs = np.array(T[\"G_BPmag\"] - T[\"G_RPmag\"])  # color1 = BP - RP\n",
    "color2_obs = None\n",
    "\n",
    "# Errores asociados\n",
    "e_mag_obs  = np.array(T[\"e_Gmag\"])\n",
    "e_col1_obs = np.array(T[\"e_BP_RP\"]) if \"e_BP_RP\" in T.colnames else (\n",
    "    np.hypot(np.array(T[\"e_G_BPmag\"]), np.array(T[\"e_G_RPmag\"])))\n",
    "e_col2_obs = None\n",
    "\n",
    "# Chequeo de tamaños\n",
    "print(\"Obs sizes:\",\n",
    "      len(mag_obs), len(color1_obs),\n",
    "      None if color2_obs is None else len(color2_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bab9d1-300c-4dd9-933f-0d1ee568c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asteca\n",
    "isochs = asteca.Isochrones(isochs_path=\"/Users/notluquis/Library/Mobile Documents/com~apple~CloudDocs/Investigación/NGC6383/MIST\",\n",
    "                           model='MIST',\n",
    "                           magnitude=\"Gaia_G_EDR3\",\n",
    "                           magnitude_effl=6390.7,\n",
    "                           color=(\"Gaia_BP_EDR3\",\"Gaia_RP_EDR3\"),\n",
    "                           color_effl = (5182.6,7825.1),\n",
    "                           #color2 = (\"Gaia_RP_EDR3\",\"2MASS_J\"),\n",
    "                           #color2_effl = (7825.1, 12375.60),\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c165dbb5-a15d-4a1f-a8ee-208693eadc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "theor_tracks, color_filters, met_age_dict = isochs.theor_tracks, isochs.color_filters, isochs.met_age_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec75a4-7fcc-4e30-9478-a12a712c7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_imf_cached_pkl(cache_path: str,\n",
    "                              rng_seed: int,\n",
    "                              IMF_name: str,\n",
    "                              max_mass: float,\n",
    "                              Nmets: int,\n",
    "                              Nages: int):\n",
    "    \"\"\"\n",
    "    Carga st_dist_mass (+ ordered) desde un .pkl si es compatible con la malla actual.\n",
    "    Si no existe / no coincide la metadata, recalcula, guarda y devuelve.\n",
    "    \"\"\"\n",
    "    meta_new = dict(\n",
    "        rng_seed=int(rng_seed),\n",
    "        IMF_name=str(IMF_name),\n",
    "        max_mass=float(max_mass),\n",
    "        Nmets=int(Nmets),\n",
    "        Nages=int(Nages),\n",
    "    )\n",
    "\n",
    "    obj = load_pkl(cache_path)\n",
    "    st = obj[\"st_dist_mass\"]\n",
    "    sto = obj.get(\"st_dist_mass_ordered\", None)\n",
    "    meta_old = obj.get(\"meta\", {})\n",
    "    return st,sto,meta_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a4a9bc-af7d-4303-87ce-379cd8fc6980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# USO con tus variables\n",
    "# =========================\n",
    "Nmets   = len(met_age_dict[\"met\"])\n",
    "Nages   = len(met_age_dict[\"loga\"])\n",
    "rng_seed = 42\n",
    "IMF_name = \"kroupa_2001\"\n",
    "Max_mass = 2.5e5\n",
    "\n",
    "cache_path = '/Users/notluquis/Library/Mobile Documents/com~apple~CloudDocs/Investigación/COSMIC/COSMIC/precomp/st_imf.pkl'\n",
    "\n",
    "#st_dist_mass, st_dist_mass_ordered, meta = get_sample_imf_cached_pkl(\n",
    "st_dist_mass, st_dist_mass_ordered = get_sample_imf_cached_pkl(\n",
    "    cache_path=cache_path,\n",
    "    rng_seed=rng_seed,\n",
    "    IMF_name=IMF_name,\n",
    "    max_mass=Max_mass,\n",
    "    Nmets=Nmets,\n",
    "    Nages=Nages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf3725-aa95-43e0-856f-a4186d202292",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_dist_mass, st_dist_mass_ordered, meta = obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b0d7d6-2ab4-46d6-a9ac-76ac30a060f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(st_dist_mass) =\", len(st_dist_mass))\n",
    "print(\"len(st_dist_mass[0]) =\", len(st_dist_mass[0]))\n",
    "print(\"Fingerprint ejemplo:\",\n",
    "      len(st_dist_mass[0][0]),\n",
    "      np.nanmin(st_dist_mass[0][0]),\n",
    "      np.nanmax(st_dist_mass[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942cd1eb-ed19-42cf-8481-b1ce8b5842f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asteca.modules import synth_cluster_priv as scp\n",
    "\n",
    "# --- Celda 5: valores aleatorios congelados para test/validación ---\n",
    "# Estos NO se usarán dentro de NUTS (ahí haremos todo determinista),\n",
    "# pero sirven para validar equivalencias con tu pipeline original.\n",
    "\n",
    "# Usa el mismo tamaño que el mayor número de estrellas que vayas a sintetizar\n",
    "N_max = max(len(mag_obs), 10_000)\n",
    "\n",
    "rand_norm_vals = np.array([\n",
    "    rng.normal(0.0, 1.0, N_max),  # canal 0\n",
    "    rng.normal(0.0, 1.0, N_max)   # canal 1 (si necesitas otro)\n",
    "])\n",
    "rand_unif_vals = np.array([\n",
    "    rng.uniform(0.0, 1.0, N_max),\n",
    "    rng.uniform(0.0, 1.0, N_max)\n",
    "])\n",
    "\n",
    "# Si quieres generar un err_dist \"congelado\" sólo para validaciones:\n",
    "err_dist = scp.error_distribution(\n",
    "    mag=mag_obs,\n",
    "    e_mag=e_mag_obs,\n",
    "    e_color=e_col1_obs,\n",
    "    e_color2=None,\n",
    "    rand_norm_vals=rand_norm_vals[0]\n",
    ")\n",
    "print(\"err_dist sizes:\", [len(x) for x in err_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda64934-73e6-4275-90ae-40c0a03259e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def collapse_duplicates_strict(x, y, keep=\"last\"):\n",
    "    x = np.asarray(x, float); y = np.asarray(y, float)\n",
    "    order = np.argsort(x, kind=\"mergesort\")\n",
    "    xo, yo = x[order], y[order]\n",
    "\n",
    "    if keep == \"first\":\n",
    "        xs, idx = np.unique(xo, return_index=True)\n",
    "        ys = yo[idx]\n",
    "    elif keep == \"last\":\n",
    "        xr, yr = xo[::-1], yo[::-1]\n",
    "        _, idxr = np.unique(xr, return_index=True)  # first in reversed == last in original\n",
    "        idx = (xr.size - 1) - idxr\n",
    "        idx.sort()\n",
    "        xs, ys = xo[idx], yo[idx]\n",
    "    else:\n",
    "        raise ValueError(\"keep must be 'first' or 'last'\")\n",
    "\n",
    "    if not np.all(np.diff(xs) > 0):\n",
    "        raise RuntimeError(\"xs is not strictly increasing after collapsing duplicates.\")\n",
    "    return xs, ys\n",
    "\n",
    "def linear_interp_matrix(xq, x):\n",
    "    \"\"\"\n",
    "    Build a sparse matrix W such that (W @ y) == np.interp(xq, x, y)\n",
    "    for any vector y sampled on strictly increasing grid x.\n",
    "    \"\"\"\n",
    "    x  = np.asarray(x,  float)\n",
    "    xq = np.asarray(xq, float)\n",
    "    if np.any(~np.isfinite(x)) or np.any(~np.isfinite(xq)):\n",
    "        raise ValueError(\"Non-finite values in x/xq are not supported.\")\n",
    "    if not np.all(np.diff(x) > 0):\n",
    "        raise ValueError(\"x must be strictly increasing (no duplicates).\")\n",
    "\n",
    "    n = x.size\n",
    "    m = xq.size\n",
    "    j  = np.searchsorted(x, xq, side='right')\n",
    "    j  = np.clip(j, 1, n-1)\n",
    "    i0 = j - 1\n",
    "\n",
    "    x0 = x[i0]; x1 = x[j]\n",
    "    w1 = (xq - x0) / (x1 - x0)\n",
    "    w0 = 1.0 - w1\n",
    "\n",
    "    # filas correctas: [0..m-1] para el bloque izquierdo y derecho\n",
    "    rows = np.concatenate([np.arange(m), np.arange(m)])\n",
    "    cols = np.concatenate([i0, j])\n",
    "    data = np.concatenate([w0, w1])\n",
    "\n",
    "    return csr_matrix((data, (rows, cols)), shape=(m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300759e9-c368-4a2a-a3fd-b00707509ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# TEST con tus variables\n",
    "# =============================\n",
    "Nmets, Nages = theor_tracks.shape[:2]\n",
    "Zidx = 0  # o el que quieras\n",
    "Aidx = 0  # o el que quieras\n",
    "\n",
    "m_ini_idx  = theor_tracks.shape[2] - 1\n",
    "Mini_k_raw = np.asarray(theor_tracks[Zidx, Aidx, m_ini_idx], float)\n",
    "mag_k_raw  = np.asarray(theor_tracks[Zidx, Aidx, 0],       float)\n",
    "\n",
    "# 1) ordenar + colapsar duplicados (quedarse con el ÚLTIMO)\n",
    "xs, ys = collapse_duplicates_strict(Mini_k_raw, mag_k_raw, keep=\"last\")\n",
    "\n",
    "# 2) masses del IMF y clip al rango de xs\n",
    "xq = np.asarray(st_dist_mass[Zidx][Aidx], float)\n",
    "xq = np.clip(xq, xs[0], xs[-1])\n",
    "\n",
    "# 3) construir W y comparar con np.interp en la MISMA base (xs, ys)\n",
    "W   = linear_interp_matrix(xq, xs)     # <-- usa el nombre correcto\n",
    "lhs = W @ ys\n",
    "rhs = np.interp(xq, xs, ys)\n",
    "\n",
    "max_abs_err = float(np.max(np.abs(lhs - rhs)))\n",
    "row_sums = np.asarray(W.sum(axis=1)).ravel()\n",
    "\n",
    "print(\"interp check (∞-norm):\", max_abs_err)\n",
    "print(\"row sums min/max:\", row_sums.min(), row_sums.max())\n",
    "\n",
    "assert max_abs_err < 1e-8, \"Interpolation mismatch exceeds tolerance\"\n",
    "assert np.allclose(row_sums, 1.0, atol=1e-12), \"Each row of W must sum to 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11313b18-8c0a-4878-95e6-f8c69199f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Zi in range(theor_tracks.shape[0]):\n",
    "    for Ai in range(theor_tracks.shape[1]):\n",
    "        xs, ys = collapse_duplicates_strict(theor_tracks[Zi, Ai, m_ini_idx],\n",
    "                                            theor_tracks[Zi, Ai, 0],\n",
    "                                            keep=\"last\")\n",
    "        xq = np.clip(np.asarray(st_dist_mass[Zi][Ai], float), xs[0], xs[-1])\n",
    "        W   = linear_interp_matrix(xq, xs)\n",
    "        lhs = W @ ys\n",
    "        rhs = np.interp(xq, xs, ys)\n",
    "        err = float(np.max(np.abs(lhs - rhs)))\n",
    "        rows = np.asarray(W.sum(axis=1)).ravel()\n",
    "        if not (err < 1e-8 and np.allclose(rows, 1.0, atol=1e-12)):\n",
    "            raise AssertionError(f\"Falla en (Z={Zi}, A={Ai}): err={err}, \"\n",
    "                                 f\"rows[{rows.min()}, {rows.max()}])\")\n",
    "print(\"OK en toda la malla.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143902a-af6e-4e33-8f7e-07ef45f9bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "theor_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714f91e-74d5-4a3b-a629-8adf6775f27a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Paso 2: check apply_extinction NumPy vs Torch\n",
    "# ============================================\n",
    "import numpy as np\n",
    "from asteca.modules import synth_cluster_priv as scp\n",
    "\n",
    "# --- Selección de celda y parámetros fijos (sin DR) ---\n",
    "Zidx, Aidx = 0, 0\n",
    "fit_params = {\n",
    "    \"met\": float(met_age_dict[\"met\"][Zidx]),\n",
    "    \"loga\": float(met_age_dict[\"loga\"][Aidx]),\n",
    "    \"alpha\": 0.1, \"beta\": 1.0,\n",
    "    \"Av\": 0.3, \"DR\": 0.0, \"Rv\": 3.1, \"dm\": 10.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58683d-40da-4a17-a4af-f7d4c7ea1716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b022c-f24a-446f-b6a5-c7c47bd017aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "isoch_base = np.array(theor_tracks[Zidx, Aidx])   # (Nd, Ni)\n",
    "Nd = isoch_base.shape[0]\n",
    "\n",
    "# m_ini_idx: siempre la última fila disponible del isocrono base\n",
    "# (mag, color1, mass_ini) -> m_ini_idx=2 ; (mag, color1, color2, mass_ini) -> m_ini_idx=3\n",
    "m_ini_idx = Nd - 1\n",
    "\n",
    "# ¿Hay columnas de binaria ya presentes?\n",
    "# En los tracks \"crudos\" típicamente Nd=3 ó 4 → NO hay binaria aún.\n",
    "has_binary_cols = (Nd >= m_ini_idx + 3)  # requiere al menos [mass_ini, m2, mag_b, color1_b, ...]\n",
    "\n",
    "# Para este test queremos usar el isocrono tal cual:\n",
    "binar_flag = bool(has_binary_cols)\n",
    "\n",
    "# --- Mover por distancia (sin errores) ---\n",
    "isoch_moved = scp.move_isochrone(\n",
    "    isochrone=isoch_base.copy(),\n",
    "    binar_flag=binar_flag,   # ¡solo True si hay columnas de binaria!\n",
    "    m_ini_idx=m_ini_idx,\n",
    "    dm=fit_params[\"dm\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce2b98b-3a0e-4706-a8af-2a13d6f73ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ley de extinción y coeficientes ---\n",
    "ext_law = \"CCMO\"   # o \"GAIADR3\"\n",
    "if ext_law == \"CCMO\":\n",
    "    ext_coefs = scp.ccmo_ext_coeffs(\n",
    "        magnitude_effl=isochs.magnitude_effl,\n",
    "        color_effl=isochs.color_effl,\n",
    "        color2_effl=isochs.color2_effl,\n",
    "    )\n",
    "else:\n",
    "    ext_coefs = []  # GAIADR3 no usa pre-cálculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aff02a-c8a3-4b1c-a8dd-2fc53de6c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) referencia NumPy (llama a scp.extinction tal cual) ---\n",
    "def apply_extinction_np(isoch_arr: np.ndarray) -> np.ndarray:\n",
    "    return scp.extinction(\n",
    "        ext_law=ext_law,\n",
    "        ext_coefs=ext_coefs,\n",
    "        rand_norm=rand_norm_vals[0],    # tus pools congelados\n",
    "        rand_unif=rand_unif_vals[0],\n",
    "        DR_distribution=\"uniform\",\n",
    "        m_ini_idx=m_ini_idx,\n",
    "        binar_flag=binar_flag,\n",
    "        Av=fit_params[\"Av\"],\n",
    "        dr=fit_params[\"DR\"],\n",
    "        Rv=fit_params[\"Rv\"],\n",
    "        isochrone=isoch_arr.copy(),\n",
    "    )\n",
    "\n",
    "\n",
    "# --- 3) versión Torch equivalente ---\n",
    "def _dustapprox_torch(X_, Av_dr, torch):\n",
    "    # Coefs idénticos a scp.dustapprox (EDR3)\n",
    "    coeffs = {\n",
    "        \"G\":  (0.995969721536602,-0.159726460302015,0.0122380738156057,0.00090726555099859,\n",
    "               -0.0377160263914123,0.00151347495244888,-2.52364537395142e-05,\n",
    "               0.0114522658102451,-0.000936914989014318,-0.000260296774134201),\n",
    "        \"BP\": (1.15363197483424,-0.0814012991657388,-0.036013023976704,0.0192143585568966,\n",
    "               -0.022397548243016,0.000840562680547171,-1.31018008013549e-05,\n",
    "               0.00660124080271006,-0.000882247501989453,-0.000111215755291684),\n",
    "        \"RP\": (0.66320787941067,-0.0179847164933981,0.000493769449961458,-0.00267994405695751,\n",
    "               -0.00651422146709376,3.30179903473159e-05,1.57894227641527e-06,\n",
    "               -7.9800898337247e-05,0.000255679812110045,1.10476584967393e-05),\n",
    "    }\n",
    "    X2, X3 = X_*X_, X_*X_*X_\n",
    "    A2, A3 = Av_dr*Av_dr, Av_dr*Av_dr*Av_dr\n",
    "    def ext_coeff(k):\n",
    "        c = coeffs[k]\n",
    "        ay = (torch.full_like(X_, c[0]) +\n",
    "              c[1]*X_ + c[2]*X2 + c[3]*X3 +\n",
    "              c[4]*Av_dr + c[5]*A2 + c[6]*A3 +\n",
    "              c[7]*X_*Av_dr + c[9]*X_*A2 + c[8]*X2*Av_dr)\n",
    "        return ay\n",
    "    ec_G    = ext_coeff(\"G\")\n",
    "    ec_BPRP = ext_coeff(\"BP\") - ext_coeff(\"RP\")\n",
    "    return ec_G, ec_BPRP\n",
    "\n",
    "def apply_extinction_pt(\n",
    "    isoch_arr: np.ndarray,\n",
    "    *,\n",
    "    ext_law: str,\n",
    "    ext_coefs: list,\n",
    "    rand_norm_vals: np.ndarray,\n",
    "    rand_unif_vals: np.ndarray,\n",
    "    DR_distribution: str,\n",
    "    m_ini_idx: int,\n",
    "    binar_flag: bool,\n",
    "    Av: float,\n",
    "    DR: float,\n",
    "    Rv: float,\n",
    ") -> np.ndarray:\n",
    "    try:\n",
    "        import torch\n",
    "    except Exception:\n",
    "        return None  # Torch no disponible → saltar\n",
    "\n",
    "    t = torch.from_numpy(isoch_arr.copy()).to(torch.float64)\n",
    "\n",
    "    # Av con DR\n",
    "    if DR > 0.0:\n",
    "        Ns = t.shape[-1]\n",
    "        if DR_distribution == \"uniform\":\n",
    "            dr_arr = (2.0*torch.from_numpy(rand_unif_vals[:Ns]).to(torch.float64) - 1.0) * DR\n",
    "        elif DR_distribution == \"normal\":\n",
    "            dr_arr = torch.from_numpy(rand_norm_vals[:Ns]).to(torch.float64) * DR\n",
    "        else:\n",
    "            raise ValueError(f\"DR_distribution desconocida: {DR_distribution}\")\n",
    "        Av_dr = torch.clip(torch.tensor(Av, dtype=torch.float64) + dr_arr, min=0.0)\n",
    "    else:\n",
    "        Av_dr = torch.tensor(Av, dtype=torch.float64)\n",
    "\n",
    "    def _dustapprox_torch(X_, Av_dr):\n",
    "        # Coefs EDR3 idénticos a scp.dustapprox\n",
    "        coeffs = {\n",
    "            \"G\":  (0.995969721536602,-0.159726460302015,0.0122380738156057,0.00090726555099859,\n",
    "                   -0.0377160263914123,0.00151347495244888,-2.52364537395142e-05,\n",
    "                   0.0114522658102451,-0.000936914989014318,-0.000260296774134201),\n",
    "            \"BP\": (1.15363197483424,-0.0814012991657388,-0.036013023976704,0.0192143585568966,\n",
    "                   -0.022397548243016,0.000840562680547171,-0.0000131018008013549,\n",
    "                   0.00660124080271006,-0.000882247501989453,-0.000111215755291684),\n",
    "            \"RP\": (0.66320787941067,-0.0179847164933981,0.000493769449961458,-0.00267994405695751,\n",
    "                   -0.00651422146709376,0.0000330179903473159,0.00000157894227641527,\n",
    "                   -0.000079800898337247,0.000255679812110045,0.0000110476584967393),\n",
    "        }\n",
    "        X2, X3 = X_*X_, X_*X_*X_\n",
    "        A2, A3 = Av_dr*Av_dr, Av_dr*Av_dr*Av_dr\n",
    "        def ext_coeff(k):\n",
    "            c = coeffs[k]\n",
    "            ay = (torch.full_like(X_, c[0]) +\n",
    "                  c[1]*X_ + c[2]*X2 + c[3]*X3 +\n",
    "                  c[4]*Av_dr + c[5]*A2 + c[6]*A3 +\n",
    "                  c[7]*X_*Av_dr + c[9]*X_*A2 + c[8]*X2*Av_dr)\n",
    "            return ay\n",
    "        ec_G    = ext_coeff(\"G\")\n",
    "        ec_BPRP = ext_coeff(\"BP\") - ext_coeff(\"RP\")\n",
    "        return ec_G, ec_BPRP\n",
    "\n",
    "    if ext_law == \"CCMO\":\n",
    "        a_mag, b_mag = ext_coefs[0]\n",
    "        ec_mag  = torch.tensor(a_mag, dtype=torch.float64) + torch.tensor(b_mag, dtype=torch.float64)/Rv\n",
    "        a1, b1 = ext_coefs[1][0]; a2, b2 = ext_coefs[1][1]\n",
    "        ec_col1 = (torch.tensor(a1, dtype=torch.float64) + torch.tensor(b1, dtype=torch.float64)/Rv) - \\\n",
    "                  (torch.tensor(a2, dtype=torch.float64) + torch.tensor(b2, dtype=torch.float64)/Rv)\n",
    "        has_col2 = (len(ext_coefs) > 2)\n",
    "        if has_col2:\n",
    "            a1b, b1b = ext_coefs[2][0]; a2b, b2b = ext_coefs[2][1]\n",
    "            ec_col2 = (torch.tensor(a1b, dtype=torch.float64) + torch.tensor(b1b, dtype=torch.float64)/Rv) - \\\n",
    "                      (torch.tensor(a2b, dtype=torch.float64) + torch.tensor(b2b, dtype=torch.float64)/Rv)\n",
    "    elif ext_law == \"GAIADR3\":\n",
    "        X = t[1]\n",
    "        if DR > 0.0 and Av_dr.ndim == 0:\n",
    "            Av_dr = Av_dr.expand_as(X)\n",
    "        ec_mag, ec_col1 = _dustapprox_torch(X, Av_dr)\n",
    "        has_col2 = False\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown extinction law: {ext_law}\")\n",
    "\n",
    "    Ax  = ec_mag  * Av_dr\n",
    "    Ex1 = ec_col1 * Av_dr\n",
    "\n",
    "    t[0] += Ax\n",
    "    t[1] += Ex1\n",
    "\n",
    "    # Solo tocar columnas de binaria si realmente existen\n",
    "    if binar_flag and (t.shape[0] > m_ini_idx + 3):\n",
    "        t[m_ini_idx + 2] += Ax\n",
    "        t[m_ini_idx + 3] += Ex1\n",
    "\n",
    "    if ext_law == \"CCMO\" and has_col2 and (t.shape[0] > 2):\n",
    "        Ex2 = ec_col2 * Av_dr\n",
    "        t[2] += Ex2\n",
    "        if binar_flag and (t.shape[0] > m_ini_idx + 4):\n",
    "            t[m_ini_idx + 4] += Ex2\n",
    "\n",
    "    return t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c43aa-a479-41ce-8b28-d3e4a7706855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ejecutar el check ---\n",
    "out_np = apply_extinction_np(isoch_moved.copy())\n",
    "out_pt = apply_extinction_pt(\n",
    "    isoch_moved.copy(),\n",
    "    ext_law=ext_law,\n",
    "    ext_coefs=ext_coefs,\n",
    "    rand_norm_vals=rand_norm_vals[0],\n",
    "    rand_unif_vals=rand_unif_vals[0],\n",
    "    DR_distribution=\"uniform\",\n",
    "    m_ini_idx=m_ini_idx,\n",
    "    binar_flag=binar_flag,\n",
    "    Av=fit_params[\"Av\"],\n",
    "    DR=fit_params[\"DR\"],\n",
    "    Rv=fit_params[\"Rv\"],\n",
    ")\n",
    "\n",
    "if out_pt is None:\n",
    "    print(\"Torch no disponible → test saltado.\")\n",
    "else:\n",
    "    diff = float(np.max(np.abs(out_np - out_pt)))\n",
    "    print(\"extinction check: max |np - pt| =\", diff)\n",
    "    assert diff < 1e-8, \"Extinction mismatch exceeds tolerance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5b98e4-efe6-47e7-8f2a-8908f279cfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= utilidades base (torch) =========\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def to_tensor64(x, device=None):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.to(dtype=torch.float64, device=device)\n",
    "    return torch.as_tensor(x, dtype=torch.float64, device=device)\n",
    "\n",
    "# --- 1) move_isochrone (torch) ---\n",
    "def move_isochrone_pt(isoch_pt, m_ini_idx, dm, binar_flag=True):\n",
    "    # magnitud (col 0)\n",
    "    isoch_pt[0] = isoch_pt[0] + dm\n",
    "    if binar_flag:\n",
    "        # m_ini_idx+2 = magnitud de binaria (mismo layout que tu NumPy)\n",
    "        isoch_pt[m_ini_idx + 2] = isoch_pt[m_ini_idx + 2] + dm\n",
    "    return isoch_pt\n",
    "\n",
    "# --- 2) extinction CCMO (torch) ---\n",
    "def extinction_ccmo_pt(isoch_pt, m_ini_idx, Av, Rv, ext_coefs, binar_flag=True):\n",
    "    \"\"\"\n",
    "    ext_coefs = [ [a,b], [[a1,b1],[a2,b2]] , (opcional color2) ]\n",
    "    Aplica Ax = (a + b/Rv)*Av para mag y\n",
    "           Ex1 = ([a1 + b1/Rv] - [a2 + b2/Rv]) * Av para color1\n",
    "    \"\"\"\n",
    "    a_mag, b_mag = ext_coefs[0]\n",
    "    ec_mag = a_mag + b_mag / Rv\n",
    "    isoch_pt[0] = isoch_pt[0] + ec_mag * Av\n",
    "\n",
    "    (a1, b1), (a2, b2) = ext_coefs[1]\n",
    "    ec_c1 = (a1 + b1 / Rv) - (a2 + b2 / Rv)\n",
    "    isoch_pt[1] = isoch_pt[1] + ec_c1 * Av\n",
    "\n",
    "    if binar_flag:\n",
    "        isoch_pt[m_ini_idx + 2] = isoch_pt[m_ini_idx + 2] + ec_mag * Av\n",
    "        isoch_pt[m_ini_idx + 3] = isoch_pt[m_ini_idx + 3] + ec_c1 * Av\n",
    "\n",
    "    # Si tienes color2 en tracks y coeficientes:\n",
    "    if len(ext_coefs) > 2:\n",
    "        (a1c2, b1c2), (a2c2, b2c2) = ext_coefs[2]\n",
    "        ec_c2 = (a1c2 + b1c2 / Rv) - (a2c2 + b2c2 / Rv)\n",
    "        isoch_pt[2] = isoch_pt[2] + ec_c2 * Av\n",
    "        if binar_flag:\n",
    "            isoch_pt[m_ini_idx + 4] = isoch_pt[m_ini_idx + 4] + ec_c2 * Av\n",
    "    return isoch_pt\n",
    "\n",
    "# --- 3) soft histogram 1D (diferenciable) ---\n",
    "def soft_hist1d_torch(vals, edges):\n",
    "    \"\"\"\n",
    "    vals: (Ns,) tensor de magnitudes\n",
    "    edges: (B+1,) bordes crecientes\n",
    "    Devuelve lam: (B,) con asignación lineal a los dos bins vecinos.\n",
    "    \"\"\"\n",
    "    x = to_tensor64(vals)\n",
    "    e = to_tensor64(edges)\n",
    "\n",
    "    # Bin centers:\n",
    "    c = 0.5 * (e[1:] + e[:-1])   # (B,)\n",
    "    B = c.numel()\n",
    "\n",
    "    # para cada x, encontrar bin derecho respecto a centers\n",
    "    j = torch.searchsorted(c, x, right=True)  # [0..B]\n",
    "    j = torch.clamp(j, 1, B-1)                # evita extremos\n",
    "    i0 = j - 1\n",
    "\n",
    "    x0 = c[i0]       # centro izq\n",
    "    x1 = c[j]        # centro der\n",
    "    t  = (x - x0) / (x1 - x0)  # peso hacia la derecha\n",
    "    w0 = 1.0 - t\n",
    "    w1 = t\n",
    "\n",
    "    lam = torch.zeros(B, dtype=torch.float64, device=x.device)\n",
    "    lam = lam.index_add(0, i0, w0)  # acumula en i0\n",
    "    lam = lam.index_add(0, j,  w1)  # acumula en j\n",
    "    return lam  # diferenciable\n",
    "\n",
    "# --- 4) soft histogram 2D (magnitud, color) ---\n",
    "def soft_hist2d_torch(vals_x, edges_x, vals_y, edges_y):\n",
    "    \"\"\"\n",
    "    vals_x: magnitud, vals_y: color\n",
    "    edges_x: (Bx+1,), edges_y: (By+1,)\n",
    "    Devuelve lam: (Bx, By) con kernel separable triangular (outer product por estrella).\n",
    "    \"\"\"\n",
    "    x = to_tensor64(vals_x); y = to_tensor64(vals_y)\n",
    "    ex = to_tensor64(edges_x); ey = to_tensor64(edges_y)\n",
    "\n",
    "    cx = 0.5*(ex[1:]+ex[:-1])  # (Bx,)\n",
    "    cy = 0.5*(ey[1:]+ey[:-1])  # (By,)\n",
    "    Bx, By = cx.numel(), cy.numel()\n",
    "\n",
    "    # vecinos x\n",
    "    jx = torch.searchsorted(cx, x, right=True).clamp(1, Bx-1); ix0 = jx-1\n",
    "    x0 = cx[ix0]; x1 = cx[jx]\n",
    "    tx = (x - x0)/(x1 - x0); wx0 = 1.0 - tx; wx1 = tx\n",
    "\n",
    "    # vecinos y\n",
    "    jy = torch.searchsorted(cy, y, right=True).clamp(1, By-1); iy0 = jy-1\n",
    "    y0 = cy[iy0]; y1 = cy[jy]\n",
    "    ty = (y - y0)/(y1 - y0); wy0 = 1.0 - ty; wy1 = ty\n",
    "\n",
    "    lam = torch.zeros(Bx, By, dtype=torch.float64, device=x.device)\n",
    "\n",
    "    # 4 combinaciones por estrella: (ix0,iy0), (ix0,jy), (jx,iy0), (jx,jy)\n",
    "    # pesos = producto separable\n",
    "    lam.index_put_((ix0, iy0), wx0*wy0, accumulate=True)\n",
    "    lam.index_put_((ix0, jy ), wx0*wy1, accumulate=True)\n",
    "    lam.index_put_((jx,  iy0), wx1*wy0, accumulate=True)\n",
    "    lam.index_put_((jx,  jy ), wx1*wy1, accumulate=True)\n",
    "    return lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305fab2-68a0-451b-8cef-63cc300b00f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= harness de prueba (1D en magnitud; adapta a 2D si quieres) =========\n",
    "\n",
    "# 0) Observado (usa las mismas edges que tu pipeline)\n",
    "valid = np.isfinite(mag_obs)\n",
    "N_obs_np, edges_np = np.histogram(mag_obs[valid], bins=30)\n",
    "N_obs = torch.as_tensor(N_obs_np, dtype=torch.float64)\n",
    "edges = torch.as_tensor(edges_np, dtype=torch.float64)\n",
    "\n",
    "# 1) Selección de isócrona\n",
    "Zidx, Aidx = 0, 0\n",
    "tracks_np  = theor_tracks[Zidx, Aidx]             # (Nd, Ni) numpy\n",
    "tracks_pt  = to_tensor64(tracks_np)               # torch\n",
    "Nd         = tracks_pt.shape[0]\n",
    "m_ini_idx  = Nd - 1                                # igual que antes\n",
    "\n",
    "# 2) Mover + Extinguir (CCMO) sin DR\n",
    "dm = 10.0; Av = 0.3; Rv = 3.1\n",
    "binar_flag = (tracks_pt.shape[0] > (m_ini_idx + 2))  # True si hay columnas binaria\n",
    "\n",
    "# ext_coefs: llévalos como tensores (a,b) con mismo orden que en NumPy\n",
    "# ej: Gaia EDR3\n",
    "ext_coefs = [\n",
    "    (torch.tensor(0.0, dtype=torch.float64), torch.tensor(0.0, dtype=torch.float64)),  # placeholder\n",
    "    ((torch.tensor(0.0), torch.tensor(0.0)), (torch.tensor(0.0), torch.tensor(0.0)))  # placeholder\n",
    "]\n",
    "# >>> Reemplaza arriba por tus coeficientes reales (mismos que ya usaste en (2) NP/PT)\n",
    "\n",
    "iso_moved = move_isochrone_pt(tracks_pt.clone(), m_ini_idx, dm, binar_flag=binar_flag)\n",
    "iso_ext   = extinction_ccmo_pt(iso_moved, m_ini_idx, Av, Rv, ext_coefs, binar_flag=binar_flag)\n",
    "\n",
    "# 3) Magnitudes “modelo” (sin errores ni DR)\n",
    "mag_model_pt = iso_ext[0]   # (Ni,)\n",
    "\n",
    "# 4) Histograma suave (PT)\n",
    "lam_pt = soft_hist1d_torch(mag_model_pt, edges)   # (B,)\n",
    "\n",
    "# 5) Normaliza a total observado\n",
    "sum_obs = float(N_obs.sum())\n",
    "sum_mod = float(lam_pt.sum())\n",
    "if sum_mod > 0:\n",
    "    lam_pt = lam_pt * (sum_obs / sum_mod)\n",
    "else:\n",
    "    lam_pt = torch.zeros_like(lam_pt)\n",
    "\n",
    "# 6) Check de normalización\n",
    "rel_err = abs(float(lam_pt.sum()) - sum_obs)/max(1.0, sum_obs)\n",
    "print(f\"[PT] lam.sum={float(lam_pt.sum()):.6f}, N_obs.sum={sum_obs:.6f}, rel_err={rel_err:.3e}\")\n",
    "assert rel_err < 1e-8, \"Total esperado (lam.sum) debe igualar al observado\"\n",
    "\n",
    "# (Opcional) equivalencia con NumPy si tienes versión NP (soft-hess NP)\n",
    "# lam_np = ...  # tu ruta NumPy que calcule lo mismo con el mismo kernel triangular\n",
    "# diff = np.max(np.abs(lam_np - lam_pt.detach().cpu().numpy()))\n",
    "# print(\"soft_hess NP vs PT: max |lam_np - lam_pt| =\", float(diff))\n",
    "# assert diff < 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2356c-31d5-4f8f-88fe-a8a8e75b1187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a1c1a-7fba-4ca9-994f-df2b8caca76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a1cb6c-c991-45cc-ad28-6ef3afb273d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mini-checklist final\n",
    "\t•\tUsa el mismo m_ini_idx que en tu pipeline (2 si trabajas con 1 color; 3 si usas 2).\n",
    "\t•\tAsegura que Mini_k esté ordenado y sin NaNs.\n",
    "\t•\tReutiliza exactamente los mismos rand_norm_vals / rand_unif_vals entre ambas rutas (np/pt).\n",
    "\t•\tEn el test del Hessiano, si tu soft_hess_np devuelve también penalizaciones/reg., comprueba el lam antes de normalizar por regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97584c79-fc77-48ea-a437-5f1c9edd178b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36fc5f1-9eae-4d42-8d25-da568890cdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073a68e-7de4-4bc8-9c04-e472f21fd0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
